{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv1d, BatchNorm1d, ReLU, Linear\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ChordClassifier as cc\n",
    "import importlib as lib\n",
    "\n",
    "lib.reload(cc)\n",
    "settings_dict = {'in_channels': 2, \n",
    "\t\t'num_layers': 5,\n",
    "\t\t'filter_width': 11,\n",
    "\t\t'channels': [16, 32, 64, 128, 256],\n",
    "\t\t'dropout':0.2,\n",
    "\t\t'rate':44100,\n",
    "\t\t'duration':0.5,\n",
    "\t\t'flat_dim':128}\n",
    "\n",
    "net = cc.SiameseArchitecture(**settings_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in = torch.randn(4, 2, 22100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/collin/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(test_in, test_in).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in net.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34515937"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7975291609764099 acc: 0.3333333333333333\n",
      "loss: 0.6964635848999023 acc: 0.8333333333333334\n",
      "loss: 0.7176907658576965 acc: 0.3333333333333333\n",
      "loss: 0.7445562481880188 acc: 0.0\n",
      "loss: 0.6352415084838867 acc: 0.8333333333333334\n",
      "loss: 0.788937509059906 acc: 0.5\n",
      "loss: 0.6249960064888 acc: 0.6666666666666666\n",
      "loss: 0.6754755973815918 acc: 0.5\n",
      "loss: 0.6820318102836609 acc: 0.6666666666666666\n",
      "loss: 0.602455198764801 acc: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# %load train_chords.py\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib as lib\n",
    "import ChordClassifier as cc\n",
    "import torch.optim\n",
    "\n",
    "from torch.nn import Conv1d, BatchNorm1d, ReLU, Linear\n",
    "from utils import *\n",
    "from parameters import *\n",
    "\n",
    "lib.reload(cc)\n",
    "\n",
    "BATCH_SIZE = 6\n",
    "\n",
    "def make_batch(df, chord, b_s=32):\n",
    "    match_dfs = df[df.chord == chord]\n",
    "    match_dfs = match_dfs.sample(b_s)\n",
    "    diff_dfs = df[df.chord != chord]\n",
    "    diff_dfs = diff_dfs.sample(b_s)\n",
    "\n",
    "    match_x1 = []\n",
    "    match_x2 = []\n",
    "\n",
    "    diff_x1 = []\n",
    "    diff_x2 = []\n",
    "\n",
    "    for i in range(0, len(match_dfs), 2):\n",
    "        _, t = read(match_dfs.iloc[i].fname)\n",
    "        match_x1.append(t)\n",
    "\n",
    "    for j in range(1, len(match_dfs), 2):\n",
    "        _, t = read(match_dfs.iloc[i].fname)\n",
    "        match_x2.append(t)\n",
    "\n",
    "    for i in range(0, len(diff_dfs), 2):\n",
    "        _, t = read(diff_dfs.iloc[i].fname)\n",
    "        diff_x1.append(t)\n",
    "\n",
    "    for i in range(1, len(diff_dfs), 2):\n",
    "        _, t = read(diff_dfs.iloc[i].fname)\n",
    "        diff_x2.append(t)\n",
    "\n",
    "    x1 = torch.cat(match_x1 + diff_x1, 0)\n",
    "    x2 = torch.cat(match_x2 + diff_x2, 0)\n",
    "\n",
    "    y = torch.cat((torch.ones(len(match_x1), 1), torch.zeros(len(diff_x2), 1)), 0)\n",
    "    y.requires_grad = True\n",
    "\n",
    "    # indices = np.arange(len(match_x1) + len(diff_x2))\n",
    "    # np.random.shuffle(indices)\n",
    "    x1_out = x1[:,:,:]\n",
    "    x2_out = x2[:,:,:]\n",
    "    y_out = y[:,:]\n",
    "\n",
    "    return x1_out, x2_out, y_out\n",
    "\n",
    "net = cc.SiameseArchitecture(**SETTINGS)    \n",
    "\n",
    "# refset_df = pd.read_csv(REF_CSV, header=None, sep=',', names=['fname', 'chord', 'key'])    \n",
    "# refset_df.loc[:, 'fname'] = REF_DIR + refset_df[['fname']]\n",
    "# refset_df['chord'] = refset_df['chord'] + '_' + refset_df['key']\n",
    "# refset_df = refset_df.drop(columns=['key'])\n",
    "\n",
    "df = pd.read_csv(ALT_CSV, header=None, sep=',', names=['fname', 'chord', 'key'])\n",
    "df.loc[:, 'fname'] = ALT_DIR + df[['fname']]\n",
    "df['chord'] = df['chord'] + '_' + df['key']\n",
    "df = df.drop(columns=['key'])    \n",
    "\n",
    "# df = refset_df.append(df)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.000001,  amsgrad=True)\n",
    "optimizer.zero_grad()\n",
    "    \n",
    "for _ in range(0, 10):\n",
    "    x1, x2, y = make_batch(df, 'd_sharp_major', b_s=BATCH_SIZE)\n",
    "    probs = net(x1, x2)\n",
    "    loss = F.binary_cross_entropy(probs, y.detach())\n",
    "    thresh = probs > 0.5\n",
    "    acc = torch.sum(thresh == y).item() / torch.numel(y)\n",
    "\n",
    "    print('loss: {} acc: {}'.format(loss, acc))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5470489859580994 acc: 0.8333333333333334\n",
      "loss: 0.6778363585472107 acc: 0.6666666666666666\n",
      "loss: 0.5715370774269104 acc: 1.0\n",
      "loss: 0.5494368076324463 acc: 0.8333333333333334\n",
      "loss: 0.5638139843940735 acc: 1.0\n",
      "loss: 0.5791290402412415 acc: 1.0\n",
      "loss: 0.5864560008049011 acc: 0.8333333333333334\n",
      "loss: 0.552257239818573 acc: 0.8333333333333334\n",
      "loss: 0.5076869130134583 acc: 0.8333333333333334\n",
      "loss: 0.5381329655647278 acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "for _ in range(0, 10):\n",
    "    x1, x2, y = make_batch(df, 'd_sharp_major', b_s=BATCH_SIZE)\n",
    "    probs = net(x1, x2)\n",
    "    loss = F.binary_cross_entropy(probs, y.detach())\n",
    "    thresh = probs > 0.5\n",
    "    acc = torch.sum(thresh == y).item() / torch.numel(y)\n",
    "\n",
    "    print('loss: {} acc: {}'.format(loss, acc))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5478]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = '/Users/collin/Dropbox/code/VoiceSampler/chord_classification/SomeLikeItHot/'\n",
    "base2 = '/Users/collin/Downloads/songs/collin_cuts/'\n",
    "not_d = base2 + 'cw_cut1.mp3'\n",
    "is_d = base + 'slih12.mp3'\n",
    "\n",
    "_, yes_d = read(is_d)\n",
    "_, no_d = read(not_d)\n",
    "net(yes_d, no_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [1.9607e-19],\n",
       "        [1.2706e-18],\n",
       "        [7.2639e-19],\n",
       "        [5.7291e-14],\n",
       "        [1.3429e-12]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = x1[0].unsqueeze(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050\n"
     ]
    }
   ],
   "source": [
    "_, g_sh_M = read('/Users/collin/Dropbox/code/VoiceSampler/chord_classification/SomeLikeItHot/slih1.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(g_sh_M, test_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
